{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "\"\"\" Linear regression with a single feature\"\"\"\n",
    "\n",
    "class LinearRegression():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.parameters = list()\n",
    "        \n",
    "        \n",
    "    def hypothesis(self, feature, thetas):\n",
    "        \"\"\"\n",
    "        The hypothesis has the following form: h = aX + b where \" a, b\" are the parameters of our model, \n",
    "        X is the feature.\n",
    "        \"\"\"\n",
    "        return (feature * thetas[1] + thetas[0])\n",
    "    \n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        A function to calculate the error of the model. However in this example its not really useful.\n",
    "        \"\"\"\n",
    "        \n",
    "        summation = 0\n",
    "        for i in range(self.n_examples):\n",
    "            \n",
    "            diff = self.hypothesis(self.X_train[i][0]) - self.X_train[i][1]\n",
    "            squared_error = diff ** 2\n",
    "            summation = summation + squared_error\n",
    "        \n",
    "        return (1 / (2 * self.n_examples)) * summation \n",
    "                \n",
    "    def gradient_descent(self, x, y):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function is an implementation of the gradient descent algorithm. At the end it gets the good\n",
    "        parameters which fit our dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        thetas = np.zeros(2)\n",
    "        n_examples = len(x)\n",
    "        \n",
    "        #I have to reshape the training set by adding one column of 1\n",
    "        x = np.c_[np.ones(len(x)), x[:, 0]]\n",
    "        learning_rate = 0.01\n",
    "        predictions = np.dot(x, thetas)\n",
    "        \n",
    "        for i in range(5000):\n",
    "            \n",
    "            learning_rate = 0.01\n",
    "            predictions = np.dot(x, thetas)\n",
    "\n",
    "            errors = np.subtract(predictions, y)\n",
    "            element_wise = errors * x[:, 1]\n",
    "            temp0 = thetas[0] - learning_rate * ( 1/ n_examples) * (errors.sum())\n",
    "            temp1 = thetas[1] - learning_rate * ( 1 /n_examples ) * (element_wise.sum())\n",
    "\n",
    "            thetas[0] = temp0\n",
    "            thetas[1] = temp1\n",
    "        \n",
    "            predictions = np.dot(x, thetas)\n",
    "            \n",
    "        return thetas\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function is used for esthetic purposes xD. It's used so the way the model is used can be \n",
    "        similar to how its used in the scikit-learn library.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.parameters = (self.gradient_descent(x, y))\n",
    "        \n",
    "    def predict(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function is used to predict the value of an output y given an input x using the parameters \n",
    "        found by the gradient descent\n",
    "        \n",
    "        y = ax + b. a and b are our parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        y = (self.parameters[1] * x) + self.parameters[0]\n",
    "        return y       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset i used for testing is a text file. If you want to test with another dataset all you have to do is to convert it into a numpy array whose shape is (X, 2) where the first column is the feature X and the second is Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.predict(NUMBER))  #The NUMBER must be an integer or a float\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
